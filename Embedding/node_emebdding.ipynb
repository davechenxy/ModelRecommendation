{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DomainNet source task embedding\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Source task data\n",
    "source_data = [\n",
    "    [\"convnext\", \"convnext_small\", 50223688, 83.616,8.68],\n",
    "    [\"convnext\", \"convnext_tiny\", 28589128, 82.52, 4.46],\n",
    "    [\"densenet\", \"densenet121\", 7978856, 74.434, 2.83],\n",
    "    [\"efficientnet\",\"efficientnet_b0\",5288548,77.692,0.39],\n",
    "    [\"efficientnet\",\"efficientnet_b3\",12233232,82.008,1.83],\n",
    "    [\"mobilenet\", \"mobilenet_v2\", 3504872, 72.154, 0.3],\n",
    "    [\"resnet\",\"resnet101\",68883240,78.468,11.4],\n",
    "    [\"resnet\", \"resnet50\", 25557032, 80.858, 4.09],\n",
    "    [\"resnet\", \"resnet18\", 11689512, 69.758, 1.81],\n",
    "    [\"resnet\", \"wide_resnet50_2\", 44549160, 81.886, 7.8]\n",
    "]\n",
    "\n",
    "source_architecture_family = [row[0] for row in source_data]\n",
    "source_model_name = [row[1] for row in source_data]\n",
    "source_scalar_features = [[row[2], row[3], row[4]] for row in source_data]\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "source_architecture_family_one_hot = enc.fit_transform(np.array(source_architecture_family).reshape(-1, 1)).toarray()\n",
    "source_model_name_one_hot = enc.fit_transform(np.array(source_model_name).reshape(-1, 1)).toarray()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "source_scalar_features_normalized = scaler.fit_transform(source_scalar_features)\n",
    "\n",
    "source_embedding = np.concatenate((source_architecture_family_one_hot, source_model_name_one_hot, source_scalar_features_normalized), axis=1)\n",
    "np.save(\"DomainNet_source_embedding.npy\", source_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cm/shared/apps/anaconda3.10/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/cm/shared/apps/anaconda3.10/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/cm/shared/apps/anaconda3.10/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "file_path = \"./target_embedding.xlsx\"\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "datasets_name = enc.fit_transform(df[['dataset name']].values)\n",
    "domain_one_hot = enc.fit_transform(df[['domain']].values)\n",
    "categories_one_hot = enc.fit_transform(df[['categories']].values)\n",
    "\n",
    "train_sample_size_normalized = scaler.fit_transform(df[['Train_Sample_Size']].values.reshape(-1, 1))\n",
    "num_pre_class_normalized = scaler.fit_transform(df[['num_pre_class']].values.reshape(-1, 1))\n",
    "\n",
    "processed_data = np.concatenate([datasets_name, domain_one_hot, num_pre_class_normalized, categories_one_hot, train_sample_size_normalized], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embedding = np.concatenate((processed_data, FM_embedding), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "source_dim = s_embedding.shape[1]  # 13\n",
    "target_dim = target_embedding.shape[1]  # 33\n",
    "\n",
    "new_dim = source_dim + target_dim  # 46\n",
    "\n",
    "new_source_embedding = np.zeros((s_embedding.shape[0], new_dim))\n",
    "new_target_embedding = np.zeros((target_embedding.shape[0], new_dim))\n",
    "\n",
    "new_source_embedding[:, :source_dim] = s_embedding\n",
    "\n",
    "new_target_embedding[:, source_dim:] = target_embedding\n",
    "\n",
    "np.save('DomainNet_new_source_embedding.npy', new_source_embedding)\n",
    "np.save('DomainNet_new_target_embedding.npy', new_target_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"target_domain_embedding.npy\", processed_data)\n",
    "\n",
    "# processed_df = pd.DataFrame(processed_data)\n",
    "# processed_df.to_excel(\"processed_data.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"./target_embedding.xlsx\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DomainNet target task embedding\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Target task data\n",
    "target_data = [\n",
    "    [\"Domain Net_subset_1\", \"sketch\", 2, 121, 110,],\n",
    "    [\"Domain Net_subset_2\", \"sketch\", 4, 400, 349,],\n",
    "    [\"Domain Net_subset_3\", \"sketch\", 6, 600, 600,],\n",
    "]\n",
    "\n",
    "\n",
    "target_dataset_name = [row[0] for row in target_data]\n",
    "target_domain_name = [row[1] for row in target_data]\n",
    "target_scalar_features = [[row[2], row[3], row[4]] for row in target_data]\n",
    "\n",
    "target_scalar_features_normalized = scaler.fit_transform(target_scalar_features)\n",
    "target_dataset_name_one_hot = enc.fit_transform(np.array(target_dataset_name).reshape(-1, 1)).toarray()\n",
    "target_domain_name_one_hot = enc.fit_transform(np.array(target_domain_name).reshape(-1, 1)).toarray()\n",
    "\n",
    "target_embedding = np.concatenate((target_dataset_name_one_hot, target_domain_name_one_hot, target_scalar_features_normalized), axis=1)\n",
    "\n",
    "np.save(\"target_embedding.npy\", target_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "source_dim = s_embedding.shape[1]  # 13\n",
    "target_dim = target_embedding.shape[1]  # 33\n",
    "\n",
    "new_dim = source_dim + target_dim  # 46\n",
    "\n",
    "new_source_embedding = np.zeros((s_embedding.shape[0], new_dim))\n",
    "new_target_embedding = np.zeros((target_embedding.shape[0], new_dim))\n",
    "\n",
    "new_source_embedding[:, :source_dim] = s_embedding\n",
    "\n",
    "new_target_embedding[:, source_dim:] = target_embedding\n",
    "\n",
    "np.save('DomainNet_new_source_embedding.npy', new_source_embedding)\n",
    "np.save('DomainNet_new_target_embedding.npy', new_target_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
